import yfinance as yf
import json
import os
import time
import random
from datetime import datetime
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# --- NLTK VADER Kurulumu (Ä°lk Ã§alÄ±ÅŸmada indirir) ---
try:
    nltk.data.find('vader_lexicon')
except LookupError:
    nltk.download('vader_lexicon')

# Sentiment Motorunu BaÅŸlat
analyzer = SentimentIntensityAnalyzer()

# --- ðŸ”¥ SAZLIK 500: DEV LÄ°STE ---
WATCHLIST = [
 "AAPL", "MSFT", "GOOGL", "GOOG", "AMZN", "NVDA", "META", "TSLA", "AVGO", "ADBE", 
    "CRM", "CMCSA", "QCOM", "TXN", "AMGN", "INTC", "CSCO", "VZ", "T", "TMUS",
    "NFLX", "ORCL", "MU", "IBM", "PYPL", "INTU", "AMD", "FTNT", "ADI", "NOW",
    "LRCX", "MRVL", "CDNS", "SNPS", "DXCM", "KLAC", "ROST", "ANSS", "MSCI", "CHTR",
    
    # --- FÄ°NANS & FÄ°NANSAL HÄ°ZMETLER ---
    "JPM", "V", "MA", "BAC", "WFC", "GS", "MS", "SPY", "BLK", "SCHW",
    "C", "AXP", "CB", "MMC", "AON", "CME", "ICE", "PGR", "ALL", "MET",
    "AIG", "PNC", "USB", "BK", "COF", "DFS", "TRV", "MCO", "CBOE", "RJF",
    "GPN", "FIS", "ZION", "FITB", "STT", "NDAQ", "RF", "KEY", "CFG", "HBAN",
    
    # --- SAÄžLIK & Ä°LAÃ‡ ---
    "JNJ", "LLY", "UNH", "ABBV", "MRK", "PFE", "DHR", "TMO", "MDT", "SYK",
    "AMGN", "GILD", "BIIB", "VRTX", "BMY", "ISRG", "ABT", "ZTS", "BDX", "BSX",
    "CI", "CVS", "HUM", "HCA", "ANTM", "LH", "COO", "ALGN", "HOLX", "DVA",
    "WAT", "RGEN", "IQV", "REGN", "EW", "TECH", "PKI", "DGX", "INCY", "CRL",
    
    # --- TEMEL TÃœKETÄ°M & DAYANIKLI TÃœKETÄ°M (Ä°stikrar) ---
    "PG", "KO", "PEP", "WMT", "COST", "HD", "MCD", "NKE", "LOW", "TGT",
    "SBUX", "MDLZ", "CL", "PM", "MO", "KR", "DG", "ADBE", "EL", "KHC",
    "GIS", "K", "SYY", "APO", "DECK", "BBY", "WHR", "NWSA", "FOXA", "HAS",
    "MAT", "HOG", "GT", "TIF", "TPR", "TTC", "VFC", "HBI", "KSS", "ULTA",
    
    # --- ENERJÄ° & SANAYÄ° (KÃ¶klÃ¼ Åžirketler) ---
    "XOM", "CVX", "BRK.B", "LMT", "RTX", "BA", "HON", "MMM", "GE", "GD",
    "CAT", "DE", "EOG", "OXY", "SLB", "COP", "PSX", "MPC", "WMB", "KMI",
    "ETN", "AOS", "EMR", "PCAR", "ROK", "SWK", "TDY", "RSG", "WM", "CARR",
    "ITW", "GWW", "WAB", "IEX", "AAL", "DAL", "UAL", "LUV", "HA", "ALK",
    
    # --- EMLAK, KAMU HÄ°ZMETLERÄ° & DÄ°ÄžER (Ã‡eÅŸitlilik) ---
    "DUK", "NEE", "SO", "EXC", "AEP", "SRE", "WEC", "D", "ED", "XEL",
    "VNQ", "SPG", "PLD", "EQIX", "AMT", "CCI", "HST", "O", "ARE", "PSA",
    "WY", "BXP", "REG", "VTR", "AVB", "ESR", "EPR", "KIM", "FRT", "APTS",
    "LUMN", "VIAC", "FOX", "DISCA", "ETSY", "EBAY", "ATVI", "EA", "TTWO", "ZG"

    # --- YARI Ä°LETKEN & BULUT BÄ°LÄ°ÅžÄ°M ---
    "ASML", "AMAT", "TSM", "MCHP", "TER", "U", "VEEV", "OKTA", "NET", "CRWD", 
    "DDOG", "ZS", "TEAM", "ADSK", "MSI", "FTV", "WDC", "ZBRA", "SWKS", "QDEL",

    # --- YENÄ°LENEBÄ°LÄ°R ENERJÄ° & EV (Elektrikli AraÃ§lar) ---
    "FSLY", "PLUG", "ENPH", "SEDG", "RUN", "SPWR", "BLDP", "FCEL", "BE", "SOL",
    "LI", "NIO", "XPEV", "RIVN", "LCID", "NKLA", "WKHS", "QS", "ARVL", "GOEV",

    # --- FÄ°NANSAL TEKNOLOJÄ° (FinTech) & Dijital Ã–deme ---
    "SQ", "COIN", "HOOD", "UPST", "AFRM", "SOFI", "MQ", "BILL", "TOST", "PAYA",
    "DWAC", "BRZE", "AVLR", "DOCU", "SABR", "TTEC", "TWLO", "RNG", "ZM", "COUP",
    
    # --- BÄ°YOTEKNOLOJÄ° & SAÄžLIK (YÃ¼ksek BÃ¼yÃ¼me) ---
    "MRNA", "PFE", "BIIB", "VRTX", "REGN", "GILD", "AMGN", "BMRN", "ALXN", "CTAS",
    "CORT", "EXEL", "IONS", "XBI", "LABU", "EDIT", "BEAM", "NTLA", "CRSP", "ALLK",

    # --- E-TÄ°CARET & YENÄ° MEDYA ---
    "MELI", "ETSY", "ROKU", "PTON", "SPOT", "CHWY", "ZM", "DOCU", "DDOG", "FVRR",
    "PINS", "SNAP", "TWTR", "WIX", "SHOP", "SE", "BABA", "JD", "BIDU", "PDD",

    # --- ENDÃœSTRÄ° & OTOMASYON (Orta Ã–lÃ§ekli ve Dinamik) ---
    "ROP", "TT", "Ametek", "FLR", "HUBB", "APH", "ECL", "SHW", "PPG", "FMC",
    "MOS", "CF", "NUE", "STLD", "ALK", "AAL", "DAL", "LUV", "UAL", "SAVE",
    "CAR", "RCL", "CCL", "NCLH", "MGM", "WYNN", "LVS", "PENN", "DKNG", "BYND",

    # --- Ã‡EÅžÄ°TLÄ° DÄ°NAMÄ°K BÃœYÃœME (Mid-Cap/IPO) ---
    "RBLX", "UBER", "LYFT", "ABNB", "DOX", "GPN", "FLT", "PRU", "MET", "L",
    "VLO", "PSX", "MPC", "DVN", "APA", "MRO", "EOG", "OXY", "SLB", "HAL",
    "BKR", "FTI", "NOV", "TDW", "PAGP", "ENLC", "PAA", "WES", "WMB", "KMI",
    "ETN", "AOS", "EMR", "PCAR", "ROK", "SWK", "TDY", "RSG", "WM", "CARR"
]

ARCHIVE_FILE = 'news_archive.json'

def load_archive():
    if os.path.exists(ARCHIVE_FILE):
        try:
            with open(ARCHIVE_FILE, 'r') as f:
                return json.load(f)
        except:
            return []
    return []

def save_archive(data):
    with open(ARCHIVE_FILE, 'w') as f:
        json.dump(data, f, indent=4)

def analyze_sentiment(text):
    """Metni analiz eder ve Duygu Durumunu dÃ¶ndÃ¼rÃ¼r."""
    if not text: return "NÃ¶tr ðŸ˜", 0
    
    # VADER SkorlamasÄ± (-1 ile +1 arasÄ±)
    scores = analyzer.polarity_scores(text)
    compound = scores['compound']
    
    if compound >= 0.05:
        return "Olumlu ðŸŸ¢", compound
    elif compound <= -0.05:
        return "Olumsuz ðŸ”´", compound
    else:
        return "NÃ¶tr âšª", compound

def parse_news_data(news_item):
    title = None
    link = None
    date_str = datetime.now().strftime('%Y-%m-%d')

    if 'title' in news_item:
        title = news_item['title']
        link = news_item.get('link')
    elif 'content' in news_item:
        content = news_item['content']
        title = content.get('title')
        if 'clickThroughUrl' in content:
            link = content['clickThroughUrl'].get('url')
    
    if not title: return None

    # Tarih Ã‡Ã¶zÃ¼mleme
    if 'providerPublishTime' in news_item:
        date_str = datetime.fromtimestamp(news_item['providerPublishTime']).strftime('%Y-%m-%d')
    
    return {"title": title, "link": link, "date": date_str}

def fetch_sweet_spots():
    print(f"ðŸ‡ºðŸ‡¸ SazlÄ±k Haber Botu + AI Sentiment BaÅŸlatÄ±lÄ±yor...")
    
    archive_data = load_archive()
    existing_fingerprints = {f"{item.get('ticker')}_{item.get('content')}" for item in archive_data}
    
    total_new = 0
    
    # Listeyi karÄ±ÅŸtÄ±r (Her seferinde aynÄ± sÄ±rayla gidip ban yemeyelim)
    random.shuffle(WATCHLIST)
    
    for ticker in WATCHLIST:
        print(f"ðŸ“° {ticker}...", end=" ", flush=True)
        try:
            stock = yf.Ticker(ticker)
            news_list = stock.news
            
            if not news_list:
                print("ðŸ“­", end=" ") 
                time.sleep(random.uniform(1, 2))
                continue
            
            count = 0
            for raw_news in news_list:
                clean = parse_news_data(raw_news)
                if not clean: continue

                # --- 30 GÃœN KURALI (BURAYI GÃœNCELLEDÄ°K) ---
                try:
                    # Tarih formatÄ± bazen deÄŸiÅŸebilir, o yÃ¼zden try-except ÅŸart
                    news_dt = datetime.strptime(clean['date'], '%Y-%m-%d')
                    days_diff = (datetime.now() - news_dt).days
                    
                    if days_diff > 30: # 30 GÃ¼nden eski haberi alma!
                        continue
                except: 
                    pass # Tarih hesaplanamazsa haberi al (GÃ¼venli taraf)

                fingerprint = f"{ticker}_{clean['title']}"
                
                if fingerprint not in existing_fingerprints:
                    # Sentiment Analizi
                    sentiment_label, sentiment_score = analyze_sentiment(clean['title'])
                    
                    entry = {
                        "date": clean['date'],
                        "ticker": ticker,
                        "content": clean['title'],
                        "link": clean['link'],
                        "ai_sentiment": sentiment_label,
                        "sentiment_score": sentiment_score
                    }
                    archive_data.append(entry)
                    existing_fingerprints.add(fingerprint)
                    total_new += 1
                    count += 1
            
            if count > 0: print(f"âœ… {count} Yeni Haber")
            else: print("ðŸ’¤")
            
            time.sleep(random.uniform(2, 4))

        except Exception as e:
            print(f"âŒ")
            time.sleep(3)

        # Her 10 hissede bir kaydet (Veri kaybÄ±nÄ± Ã¶nlemek iÃ§in)
        if total_new > 0 and total_new % 5 == 0:
             save_archive(archive_data)

    # DÃ¶ngÃ¼ bitince son kayÄ±t
    if total_new > 0:
        archive_data.sort(key=lambda x: x['date'], reverse=True)
        save_archive(archive_data)
        print(f"\nðŸ’¾ TOPLAM {total_new} YENÄ° HABER VE ANALÄ°ZÄ° KAYDEDÄ°LDÄ°.")
    else:
        print("\nðŸ’¤ Yeni haber yok.")

if __name__ == "__main__":
    fetch_sweet_spots()