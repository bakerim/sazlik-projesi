import yfinance as yf
import pandas as pd
import json
import os
import time
from datetime import datetime

# --- ğŸ”¥ SAZLIK AVCI LÄ°STESÄ° (PASTANIN EN TATLI YERÄ°) ---
# Swing Trade iÃ§in hacmi yÃ¼ksek, habere duyarlÄ± ve agresif hisseler.
WATCHLIST = [
    # > TEKNOLOJÄ° DEVLERÄ° (Piyasa YapÄ±cÄ±lar)
    'NVDA', 'TSLA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NFLX',
    
    # > YARI Ä°LETKEN & Ã‡Ä°P (En YÃ¼ksek Volatilite BuradadÄ±r)
    'AMD', 'INTC', 'ARM', 'QCOM', 'MU', 'AVGO', 'TSM', 'SMCI',
    
    # > KRÄ°PTO & FINTECH (Bitcoin Hareketine DuyarlÄ±)
    'COIN', 'MSTR', 'MARA', 'RIOT', 'HOOD', 'PYPL', 'SQ',
    
    # > YAPAY ZEKA & YAZILIM (BÃ¼yÃ¼me OdaklÄ±)
    'PLTR', 'SNOW', 'CRWD', 'PANW', 'ORCL', 'ADBE', 'CRM', 'PATH',
    
    # > ELEKTRÄ°KLÄ° ARAÃ‡ & ENERJÄ° (Gelecek Vizyonu)
    'RIVN', 'LCID', 'NIO', 'FSLR', 'ENPH',
    
    # > Ã‡Ä°N DEVLERÄ° (YÃ¼ksek Risk/Getiri)
    'BABA', 'PDD', 'BIDU'
]

ARCHIVE_FILE = 'news_archive.json'

def load_archive():
    if os.path.exists(ARCHIVE_FILE):
        try:
            with open(ARCHIVE_FILE, 'r') as f:
                return json.load(f)
        except:
            return []
    return []

def save_archive(data):
    with open(ARCHIVE_FILE, 'w') as f:
        json.dump(data, f, indent=4)

def fetch_sweet_spots():
    print(f"ğŸ‡ºğŸ‡¸ ABD BorsasÄ± TaranÄ±yor... Hedef: {len(WATCHLIST)} Agresif Hisse")
    
    archive_data = load_archive()
    
    # MÃ¼kerrer kayÄ±t Ã¶nlemek iÃ§in mevcut baÅŸlÄ±klarÄ± hafÄ±zaya al
    existing_fingerprints = {f"{item['ticker']}_{item['content']}" for item in archive_data}
    
    new_entries_count = 0
    
    # Hepsini tek seferde Ã§ekmek yerine hisse hisse geziyoruz
    for ticker in WATCHLIST:
        try:
            # Ticker nesnesi oluÅŸtur
            stock = yf.Ticker(ticker)
            news_list = stock.news
            
            if not news_list:
                continue
                
            print(f" -> {ticker} sinyalleri kontrol ediliyor...")
            
            for news in news_list:
                title = news.get('title')
                link = news.get('link')
                pub_time = news.get('providerPublishTime')
                
                # Tarih damgasÄ± yoksa atla
                if not pub_time: continue
                
                date_str = datetime.fromtimestamp(pub_time).strftime('%Y-%m-%d')
                
                # Sadece SON 3 GÃœNÃœN haberlerini al (Ã‡ok eski haber bayattÄ±r)
                news_date = datetime.fromtimestamp(pub_time)
                days_diff = (datetime.now() - news_date).days
                if days_diff > 3:
                    continue

                # Benzersiz kimlik oluÅŸtur
                fingerprint = f"{ticker}_{title}"
                
                if title and fingerprint not in existing_fingerprints:
                    entry = {
                        "date": date_str,
                        "ticker": ticker,
                        "content": title,
                        "link": link,
                        "ai_sentiment": "Analiz Bekliyor", # HenÃ¼z AI bakmadÄ±
                        "crawled_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }
                    archive_data.append(entry)
                    existing_fingerprints.add(fingerprint)
                    new_entries_count += 1
                    print(f"    ğŸ”¥ [YENÄ°] {ticker}: {title[:40]}...")
            
            # API'yi boÄŸmamak iÃ§in minik bir nefes al
            time.sleep(0.5)
                    
        except Exception as e:
            print(f"    âš ï¸ Hata ({ticker}): {e}")

    # DeÄŸiÅŸiklik varsa kaydet
    if new_entries_count > 0:
        # En yeni tarih en Ã¼stte olacak ÅŸekilde sÄ±rala
        archive_data.sort(key=lambda x: x['date'], reverse=True)
        save_archive(archive_data)
        print(f"\nâœ… Operasyon TamamlandÄ±: {new_entries_count} taze haber 'HafÄ±za'ya eklendi.")
    else:
        print("\nğŸ’¤ Piyasa sakin, yeni 'kaymaklÄ±' haber yok.")

if __name__ == "__main__":
    fetch_sweet_spots()
