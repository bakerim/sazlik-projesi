import yfinance as yf
import json
import os
import time
from datetime import datetime

# --- ğŸ”¥ SAZLIK AVCI LÄ°STESÄ° ---
WATCHLIST = [
    # > MUHTEÅEM 7'LÄ° & TEKNOLOJÄ° DEVLERÄ°
    'NVDA', 'TSLA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NFLX', 'ADBE', 'CRM',
    'ORCL', 'CSCO', 'INTC', 'AMD', 'QCOM', 'TXN', 'AVGO', 'MU', 'LRCX', 'AMAT',
    
    # > YÃœKSEK VOLATÄ°LÄ°TE & YAPAY ZEKA (Swing Cenneti)
    'PLTR', 'AI', 'SMCI', 'ARM', 'PATH', 'SNOW', 'DDOG', 'CRWD', 'PANW', 'ZS',
    'NET', 'MDB', 'TEAM', 'U', 'DKNG', 'ROKU', 'SQ', 'SHOP', 'PYPL', 'HOOD',
    
    # > KRÄ°PTO & BLOCKCHAIN (Bitcoin Hareketleri)
    'COIN', 'MSTR', 'MARA', 'RIOT', 'CLSK', 'HUT', 'BITF',
    
    # > ELEKTRÄ°KLÄ° ARAÃ‡ & ENERJÄ°
    'RIVN', 'LCID', 'NIO', 'XPEV', 'LI', 'FSLR', 'ENPH', 'SEDG', 'PLUG', 'FCEL',
    
    # > FÄ°NANS & BANKACILIK (Hacim DepolarÄ±)
    'JPM', 'BAC', 'WFC', 'C', 'GS', 'MS', 'BLK', 'V', 'MA', 'AXP',
    
    # > PERAKENDE & TÃœKETÄ°M (BilanÃ§o DÃ¶nemleri Ä°Ã§in)
    'WMT', 'TGT', 'COST', 'HD', 'LOW', 'NKE', 'LULU', 'SBUX', 'MCD', 'KO',
    
    # > SAÄLIK & BÄ°YOTEKNOLOJÄ° (Haber OdaklÄ±)
    'LLY', 'NVO', 'PFE', 'MRNA', 'BNTX', 'VRTX', 'REGN', 'GILD', 'AMGN', 'ISRG',
    
    # > ENDÃœSTRÄ° & SAVUNMA
    'BA', 'LMT', 'RTX', 'GE', 'CAT', 'DE', 'HON', 'UNP', 'UPS', 'FDX',
    
    # > Ã‡Ä°N & GELÄ°ÅMEKTE OLANLAR (Riskli ama KarlÄ±)
    'BABA', 'PDD', 'BIDU', 'JD', 'TCEHY',
    
    # > DÄ°ÄER POPÃœLER HÄ°SSELER
    'DIS', 'CMCSA', 'TMUS', 'VZ', 'T', 'F', 'GM', 'UBER', 'ABNB', 'DASH'
]
ARCHIVE_FILE = 'news_archive.json'

def load_archive():
    if os.path.exists(ARCHIVE_FILE):
        try:
            with open(ARCHIVE_FILE, 'r') as f:
                return json.load(f)
        except:
            return []
    return []

def save_archive(data):
    with open(ARCHIVE_FILE, 'w') as f:
        json.dump(data, f, indent=4)

def parse_news_data(news_item):
    """
    Yahoo'nun karÄ±ÅŸÄ±k veri yapÄ±sÄ±nÄ± Ã§Ã¶zen akÄ±llÄ± fonksiyon.
    Hem dÃ¼z yapÄ±yÄ± hem de 'content' iÃ§ine gÃ¶mÃ¼lÃ¼ yapÄ±yÄ± dener.
    """
    title = None
    link = None
    date_str = datetime.now().strftime('%Y-%m-%d') # VarsayÄ±lan: BugÃ¼n

    # 1. BAÅLIK VE LÄ°NKÄ° BULMA
    # YÃ¶ntem A: DÃ¼z YapÄ±
    if 'title' in news_item:
        title = news_item['title']
        link = news_item.get('link')
    
    # YÃ¶ntem B: Ä°Ã§ Ä°Ã§e YapÄ± (Senin yakaladÄ±ÄŸÄ±n durum)
    elif 'content' in news_item:
        content = news_item['content']
        title = content.get('title')
        # Link bazen 'clickThroughUrl' iÃ§indedir
        if 'clickThroughUrl' in content:
            link = content['clickThroughUrl'].get('url')
    
    if not title:
        return None # BaÅŸlÄ±k yoksa bu veriyi atla

    # 2. TARÄ°HÄ° BULMA
    # YÃ¶ntem A: Unix Timestamp
    if 'providerPublishTime' in news_item:
        ts = news_item['providerPublishTime']
        date_str = datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
    
    # YÃ¶ntem B: ISO String (Ã–rn: 2025-12-05T13:00:07Z)
    elif 'content' in news_item and 'pubDate' in news_item['content']:
        raw_date = news_item['content']['pubDate']
        try:
            # Sadece ilk 10 karakteri (YYYY-MM-DD) alÄ±p iÅŸi Ã§Ã¶zelim
            date_str = raw_date[:10]
        except:
            pass

    return {
        "title": title,
        "link": link,
        "date": date_str
    }

def fetch_sweet_spots():
    print(f"ğŸ‡ºğŸ‡¸ ABD Botu (AkÄ±llÄ± Mod) BaÅŸlatÄ±ldÄ±...")
    
    archive_data = load_archive()
    existing_fingerprints = {f"{item.get('ticker')}_{item.get('content')}" for item in archive_data}
    
    total_new = 0
    
    for ticker in WATCHLIST:
        print(f"\nğŸ” {ticker} taranÄ±yor...")
        try:
            stock = yf.Ticker(ticker)
            news_list = stock.news
            
            if not news_list:
                print(f"   âš ï¸ Liste boÅŸ.")
                continue
            
            count = 0
            for raw_news in news_list:
                # Veriyi akÄ±llÄ± fonksiyona gÃ¶nderip temiz halini alalÄ±m
                clean_data = parse_news_data(raw_news)
                
                if not clean_data:
                    continue

                # Parmak izi kontrolÃ¼ (AynÄ± haberi kaydetme)
                fingerprint = f"{ticker}_{clean_data['title']}"
                
                # Tarih KontrolÃ¼ (Son 30 gÃ¼n)
                try:
                    news_dt = datetime.strptime(clean_data['date'], '%Y-%m-%d')
                    days_diff = (datetime.now() - news_dt).days
                    if days_diff > 30:
                        continue
                except:
                    pass

                if fingerprint not in existing_fingerprints:
                    entry = {
                        "date": clean_data['date'],
                        "ticker": ticker,
                        "content": clean_data['title'],
                        "link": clean_data['link'],
                        "ai_sentiment": "Analiz Bekliyor"
                    }
                    archive_data.append(entry)
                    existing_fingerprints.add(fingerprint)
                    total_new += 1
                    count += 1
                    print(f"   âœ… [KAYDEDÄ°LDÄ°] {clean_data['date']}: {clean_data['title'][:40]}...")
            
            if count == 0:
                print("   â„¹ï¸ Yeni kayÄ±t yok (Hepsi eski veya zaten var).")
                
            time.sleep(1) 
                    
        except Exception as e:
            print(f"   âŒ Hata: {e}")

    # KAYIT
    if total_new > 0:
        print(f"\nğŸ’¾ Toplam {total_new} yeni haber arÅŸive yazÄ±lÄ±yor...")
        archive_data.sort(key=lambda x: x['date'], reverse=True)
        save_archive(archive_data)
    else:
        print("\nğŸ’¤ DeÄŸiÅŸiklik yok.")

if __name__ == "__main__":
    fetch_sweet_spots()
