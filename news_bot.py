import yfinance as yf
import json
import os
import time
from datetime import datetime

# --- ğŸ”¥ SAZLIK 100: DEV LÄ°STE ---
WATCHLIST = [
    'NVDA', 'TSLA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NFLX', 'AMD', 'INTC',
    'PLTR', 'AI', 'SMCI', 'ARM', 'PATH', 'SNOW', 'CRWD', 'PANW', 'ORCL', 'ADBE',
    'COIN', 'MSTR', 'MARA', 'RIOT', 'HOOD', 'PYPL', 'SQ', 'V', 'MA', 'JPM',
    'RIVN', 'LCID', 'NIO', 'FSLR', 'ENPH', 'XOM', 'CVX',
    'WMT', 'COST', 'TGT', 'DIS', 'BA', 'LMT', 'GE', 'PFE', 'LLY', 'NVO',
    'BABA', 'PDD', 'BIDU', 'JD', 'CSCO', 'TXN', 'AVGO', 'MU', 'LRCX', 'AMAT',
    'DDOG', 'ZS', 'NET', 'MDB', 'TEAM', 'U', 'DKNG', 'ROKU', 'SHOP',
    'CLSK', 'HUT', 'BITF', 'XPEV', 'LI', 'SEDG', 'PLUG', 'FCEL',
    'BAC', 'WFC', 'C', 'GS', 'MS', 'BLK', 'AXP',
    'HD', 'LOW', 'NKE', 'LULU', 'SBUX', 'MCD', 'KO',
    'MRNA', 'BNTX', 'VRTX', 'REGN', 'GILD', 'AMGN', 'ISRG',
    'RTX', 'CAT', 'DE', 'HON', 'UNP', 'UPS', 'FDX', 'CMCSA', 'TMUS', 'VZ', 'T', 'F', 'GM', 'UBER', 'ABNB', 'DASH'
]
WATCHLIST.sort() # Alfabetik sÄ±ralama (LoglarÄ± okumak kolay olsun)

ARCHIVE_FILE = 'news_archive.json'

def load_archive():
    if os.path.exists(ARCHIVE_FILE):
        try:
            with open(ARCHIVE_FILE, 'r') as f:
                return json.load(f)
        except:
            return []
    return []

def save_archive(data):
    with open(ARCHIVE_FILE, 'w') as f:
        json.dump(data, f, indent=4)

def parse_news_data(news_item):
    """Yahoo'nun karmaÅŸÄ±k veri yapÄ±sÄ±nÄ± Ã§Ã¶zen fonksiyon"""
    title = None
    link = None
    date_str = datetime.now().strftime('%Y-%m-%d')

    # BaÅŸlÄ±k ve Link Bulma (FarklÄ± yapÄ±larÄ± dener)
    if 'title' in news_item:
        title = news_item['title']
        link = news_item.get('link')
    elif 'content' in news_item:
        content = news_item['content']
        title = content.get('title')
        if 'clickThroughUrl' in content:
            link = content['clickThroughUrl'].get('url')
    
    if not title: return None

    # Tarih Bulma
    if 'providerPublishTime' in news_item:
        ts = news_item['providerPublishTime']
        date_str = datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
    elif 'content' in news_item and 'pubDate' in news_item['content']:
        try:
            date_str = news_item['content']['pubDate'][:10]
        except: pass
    
    return {"title": title, "link": link, "date": date_str}

def fetch_sweet_spots():
    print(f"ğŸ‡ºğŸ‡¸ SazlÄ±k 100 Botu BaÅŸlatÄ±ldÄ± ({len(WATCHLIST)} Hisse)...")
    print(f"ğŸ“… Tarama AralÄ±ÄŸÄ±: Son 10 GÃ¼n")
    
    archive_data = load_archive()
    # Parmak izi kÃ¼mesi oluÅŸtur (HÄ±z iÃ§in)
    existing_fingerprints = {f"{item.get('ticker')}_{item.get('content')}" for item in archive_data}
    
    total_new = 0
    
    for ticker in WATCHLIST:
        print(f"ğŸ” {ticker}...", end=" ", flush=True)
        try:
            stock = yf.Ticker(ticker)
            news_list = stock.news
            
            if not news_list:
                print("âš ï¸ BoÅŸ (Veri Yok)")
                time.sleep(1) # BoÅŸ olsa bile bekle
                continue
            
            count = 0
            for raw_news in news_list:
                clean = parse_news_data(raw_news)
                if not clean: continue

                # --- 10 GÃœN KURALI ---
                try:
                    news_dt = datetime.strptime(clean['date'], '%Y-%m-%d')
                    days_diff = (datetime.now() - news_dt).days
                    if days_diff > 10: # 10 GÃ¼nden eskiyi alma
                        continue
                except: pass

                fingerprint = f"{ticker}_{clean['title']}"
                
                # EÄŸer bu haber daha Ã¶nce kaydedilmemiÅŸse ekle
                if fingerprint not in existing_fingerprints:
                    entry = {
                        "date": clean['date'],
                        "ticker": ticker,
                        "content": clean['title'],
                        "link": clean['link'],
                        "ai_sentiment": "Analiz Bekliyor"
                    }
                    archive_data.append(entry)
                    existing_fingerprints.add(fingerprint)
                    total_new += 1
                    count += 1
            
            if count > 0: print(f"âœ… {count} Yeni")
            else: print("ğŸ’¤ (GÃ¼ncel)")
            
            # --- HIZ AYARI (BAN YEMEMEK Ä°Ã‡Ä°N) ---
            time.sleep(2) # 2 Saniye bekle (Ã–nceki 0.5 idi, ÅŸimdi daha gÃ¼venli)

        except Exception as e:
            print(f"âŒ Hata")
            time.sleep(2) # Hata alsa bile bekle

    if total_new > 0:
        # Tarihe gÃ¶re sÄ±rala (En yeni en Ã¼stte)
        archive_data.sort(key=lambda x: x['date'], reverse=True)
        save_archive(archive_data)
        print(f"\nğŸ’¾ TOPLAM {total_new} YENÄ° HABER ARÅÄ°VE EKLENDÄ°.")
    else:
        print("\nğŸ’¤ DeÄŸiÅŸiklik yok, veriler gÃ¼ncel.")

if __name__ == "__main__":
    fetch_sweet_spots()
